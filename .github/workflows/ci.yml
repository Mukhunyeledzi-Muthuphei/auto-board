name: Terraform Plan + Apply + Database

on:
  push:
    branches:
      - main
    paths:
      - 'flyway/**'
      - 'terraform/**'
  workflow_dispatch:

env:
  TF_CLOUD_ORGANIZATION: "auto-board"
  TF_API_TOKEN: "${{ secrets.TF_API_TOKEN }}"
  TF_WORKSPACE: "auto-board-github-actions"
  CONFIG_DIRECTORY: "./terraform"
  DB_USERNAME: "${{ secrets.DB_USERNAME }}"
  DB_PASSWORD: "${{ secrets.DB_PASSWORD }}"
  GOOGLE_SECRET: "${{ secrets.GOOGLE_CLIENT_SECRET }}"

permissions:
  id-token: write
  contents: read

jobs:
  sonarQubeApplication:
    name: Build Project
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: 21

      - name: Cache SonarQube packages
        uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
          restore-keys: ${{ runner.os }}-sonar

      - name: Cache Maven packages
        uses: actions/cache@v4
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Build and analyze code quality
        working-directory: ./api
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          mvn clean install -DskipTests
          mvn -B verify org.sonarsource.scanner.maven:sonar-maven-plugin:sonar \
            -Dsonar.projectKey=auto-board_auto-board \
            -Dsonar.login=${{ secrets.SONAR_TOKEN }} \
            -DskipTests

  build:
    name: Build Project
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: 21

      - name: Cache SonarQube packages
        uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
          restore-keys: ${{ runner.os }}-sonar

      - name: Cache Maven packages
        uses: actions/cache@v4
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Build and analyze code quality
        working-directory: ./api
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          mvn clean install -DskipTests
          mvn org.sonarsource.scanner.maven:sonar-maven-plugin:sonar \
            -Dsonar.projectKey=auto-board_auto-board \
            -Dsonar.login=${{ secrets.SONAR_TOKEN }} \
            -DskipTests

      - name: Build the project with Maven
        working-directory: ./api
        run: mvn clean package -DskipTests

      - name: Check
        run: ls -a api/target

      - name: Upload JAR
        # We upload so we can re-use same jar in next job.
        uses: actions/upload-artifact@v4
        with:
          # Name of artifact can be anything
          name: artifact
          # Relative path to jar file
          path: api/target/*.jar

      - name: üèóÔ∏è Build cli with Maven
        run: mvn clean install -DskipTests
        working-directory: ./cli

      # üîß Install AWS CLI
      - name: üîß Install AWS CLI
        run: |
          sudo apt-get install -y python3-pip
          python3 -m pip install --upgrade awscli

      # ü™£ Ensure S3 bucket exists (create if missing)
      - name: ü™£ Ensure S3 bucket exists
        run: |
          aws s3api head-bucket --bucket ${{ secrets.BUCKET_NAME }} || aws s3 mb s3://${{ secrets.BUCKET_NAME }} --region ${{ secrets.AWS_REGION }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}

      # üöÄ Disable S3 Block Public Access
      - name: üöÄ Disable Block Public Access
        run: |
          aws s3api put-public-access-block --bucket "$BUCKET_NAME" --public-access-block-configuration '{
            "BlockPublicAcls": false,
            "IgnorePublicAcls": false,
            "BlockPublicPolicy": false,
            "RestrictPublicBuckets": false
          }'
        env:
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}

      # üîì Set bucket policy to allow public read access
      - name: üîì Set public read policy
        run: |
          POLICY_JSON=$(cat <<EOF
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": "*",
                "Action": "s3:GetObject",
                "Resource": "arn:aws:s3:::${BUCKET_NAME}/*"
              }
            ]
          }
          EOF
          )
          echo "$POLICY_JSON" > policy.json
          aws s3api put-bucket-policy --bucket "$BUCKET_NAME" --policy file://policy.json
        env:
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}

      # üì§ Upload JAR to S3 with public-read ACL
      - name: üì§ Upload JAR to Public S3
        run: |
          if [ -f "./cli/target/auto-board-shell-0.0.1-SNAPSHOT.jar" ]; then
            aws s3 cp ./cli/target/auto-board-shell-0.0.1-SNAPSHOT.jar s3://$BUCKET_NAME/${GITHUB_SHA:0:7}/ --region $AWS_REGION
            echo "‚úÖ JAR uploaded successfully!"
            echo "üåç Public URL: https://$BUCKET_NAME.s3.$AWS_REGION.amazonaws.com/${GITHUB_SHA:0:7}/auto-board-shell-0.0.1-SNAPSHOT.jar"
          else
            echo "‚ùå JAR file not found, skipping upload."
          fi
        env:
          BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}



#  terraform:
#    if: github.repository != 'hashicorp-education/auto-board-github-actions'
#    name: Terraform Jobs
#    runs-on: ubuntu-latest
#    needs: build
#    permissions:
#      # so GitHub can check out this repo using the default github.token
#      contents: read
#      pull-requests: write
#    steps:
#      - name: Checkout
#        uses: actions/checkout@v3
#
#      - name: Set up Terraform
#        uses: hashicorp/setup-terraform@v2
#
#      - name: Terraform Init
#        run: terraform init
#
#      - name: Terraform Validate
#        run: terraform validate
#
#      - name: Upload Configuration
#        uses: hashicorp/tfc-workflows-github/actions/upload-configuration@v1.0.0
#        id: plan-upload
#        with:
#          workspace: ${{ env.TF_WORKSPACE }}
#          directory: ${{ env.CONFIG_DIRECTORY }}
#          speculative: true
#
#      - name: Create Plan Run
#        uses: hashicorp/tfc-workflows-github/actions/create-run@v1.0.0
#        id: plan-run
#        with:
#          workspace: ${{ env.TF_WORKSPACE }}
#          configuration_version: ${{ steps.plan-upload.outputs.configuration_version_id }}
#          plan_only: true
#
#      - name: Get Plan Output
#        uses: hashicorp/tfc-workflows-github/actions/plan-output@v1.0.0
#        id: plan-output
#        with:
#          plan: ${{ fromJSON(steps.plan-run.outputs.payload).data.relationships.plan.data.id }}
#
#      - name: Checkout Apply
#        uses: actions/checkout@v3
#
#      - name: Upload Apply Configuration
#        uses: hashicorp/tfc-workflows-github/actions/upload-configuration@v1.0.0
#        id: apply-upload
#        with:
#          workspace: ${{ env.TF_WORKSPACE }}
#          directory: ${{ env.CONFIG_DIRECTORY }}
#
#      - name: Create Apply Run
#        uses: hashicorp/tfc-workflows-github/actions/create-run@v1.0.0
#        id: apply-run
#        with:
#          workspace: ${{ env.TF_WORKSPACE }}
#          configuration_version: ${{ steps.apply-upload.outputs.configuration_version_id }}
#
#      - name: Apply
#        uses: hashicorp/tfc-workflows-github/actions/apply-run@v1.0.0
#        if: fromJSON(steps.apply-run.outputs.payload).data.attributes.actions.IsConfirmable
#        id: apply
#        with:
#          run: ${{ steps.apply-run.outputs.run_id }}
#          comment: "Apply Run from GitHub Actions CI ${{ github.sha }}"

  deploy:
    name: Deploy Jobs
    runs-on: ubuntu-latest
    needs: build

    concurrency:
      group: ${{ github.workflow }}-deploy-${{ github.ref }}
      cancel-in-progress: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Check if RDS instance exists
        id: check-rds
        run: |
          if aws rds describe-db-instances --db-instance-identifier ${{ secrets.DB_INSTANCE_IDENTIFIER }} > /dev/null 2>&1; then
            echo "DB_EXISTS=true" >> $GITHUB_ENV
          else
            echo "DB_EXISTS=false" >> $GITHUB_ENV
          fi

      - name: Wait for RDS to be available
        if: env.DB_EXISTS == 'false'
        run: |
          echo "Waiting for RDS instance to be available..."
          aws rds wait db-instance-available --db-instance-identifier ${{ secrets.DB_INSTANCE_IDENTIFIER }}

      - name: Download JAR For API Deployment
        # Download the artifact which was uploaded in the Build Archive's job
        uses: actions/download-artifact@v4
        with:
          name: artifact

      - name: Check Downloaded artifact
        run: ls -a ./

      - uses: einaregilsson/beanstalk-deploy@v22
        with:
          aws_access_key: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          aws_secret_key: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          region: ${{ secrets.AWS_REGION }}
          application_name: auto-board
          environment_name: auto-board-env
          version_label: "auto-board-${{ github.sha }}-${{ github.run_id }}"
          deployment_package: autoboard-0.0.1-SNAPSHOT.jar



  migrate:
    name: Database Migrations
    needs: deploy
    runs-on: ubuntu-latest

    concurrency:
      group: ${{ github.workflow }}-migrate-${{ github.ref }}
      cancel-in-progress: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.RDS_IAM_USER_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.RDS_IAM_USER_SECRET_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Get RDS Endpoint
        id: get-endpoint
        run: |
          ENDPOINT=$(aws rds describe-db-instances --db-instance-identifier ${{ secrets.DB_INSTANCE_IDENTIFIER }} --query 'DBInstances[0].Endpoint.Address' --output text)
          echo "RDS_ENDPOINT=$ENDPOINT" >> $GITHUB_ENV

      - name: Create Initial Database
        run: |
          docker run --rm \
            -e PGPASSWORD=${{ secrets.DB_PASSWORD }} \
            postgres:latest \
            bash -c "
              echo 'Checking if AutoBoard database exists...';
              if psql -h ${{ env.RDS_ENDPOINT }} -U ${{ secrets.DB_USERNAME }} -d postgres -tAc \"SELECT 1 FROM pg_database WHERE UPPER(datname) = 'AUTO_BOARD';\" | grep -q 1; then
                echo 'Database AutoBoard already exists';
              else
                echo 'Database AutoBoard does not exist. Creating database...';
                psql -h ${{ env.RDS_ENDPOINT }} -U ${{ secrets.DB_USERNAME }} -d postgres -c \"CREATE DATABASE auto_board;\";
              fi"

      - name: Debug Connection String
        run: |
          echo "Using connection string: jdbc:postgresql://${{ env.RDS_ENDPOINT }}:5432/${{ secrets.DB_NAME }}"

      - name: Run Flyway migrations
        run: |
          docker run --rm \
          -v $(pwd)/flyway:/flyway/sql \
          flyway/flyway migrate \
          -url="jdbc:postgresql://${{ env.RDS_ENDPOINT }}:5432/${{ secrets.DB_NAME }}" \
          -user=${{ secrets.DB_USERNAME }} \
          -password=${{ secrets.DB_PASSWORD }}

